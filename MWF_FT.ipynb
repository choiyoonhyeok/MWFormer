{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOk64cscuih0ORN3QQ6uA0T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choiyoonhyeok/MWFormer/blob/main/MWF_FT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Srs_Ru4dxXTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52406c2e-c26f-44a1-e531-f43de0881775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install wandb"
      ],
      "metadata": {
        "id": "gBC3lp45WFOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "# 로그인(최초 1회만 브라우저 인증). 이미 로그인돼 있으면 건너뜀.\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "TAIZ88DOWIgZ",
        "outputId": "cdc5a68e-684a-45cf-b3b4-ddc4ba4c03a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchoiyoonhyeok0427\u001b[0m (\u001b[33mchoiyh0427-medical-ai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU/파이썬 환경 확인"
      ],
      "metadata": {
        "id": "jgJD8nKMbpyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "YHNGuteBJtOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e11acd-07f0-4639-d1af-c0c217f5d39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug 25 18:01:14 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   45C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, platform, sys\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0ZEcrI8bmo2",
        "outputId": "6bbd1279-4cfc-418c-ab45-0f47823652fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "PyTorch: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "레포 클론"
      ],
      "metadata": {
        "id": "cB9TtweNbr-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 깔끔한 작업 디렉토리\n",
        "%cd /content\n",
        "\n",
        "# 본인 fork 레포 클론\n",
        "!git clone https://github.com/choiyoonhyeok/MWFormer.git\n",
        "%cd MWFormer\n",
        "!git rev-parse --short HEAD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33A8zu_KbsbP",
        "outputId": "af7933d3-0b4b-40c7-caba-93eda5918496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'MWFormer'...\n",
            "remote: Enumerating objects: 286, done.\u001b[K\n",
            "remote: Counting objects: 100% (286/286), done.\u001b[K\n",
            "remote: Compressing objects: 100% (266/266), done.\u001b[K\n",
            "remote: Total 286 (delta 29), reused 265 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (286/286), 24.33 MiB | 17.21 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n",
            "/content/MWFormer\n",
            "5128e95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "필수 라이브러리 설치"
      ],
      "metadata": {
        "id": "nXqEsyecbzbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# requirements.txt 있으면 설치\n",
        "!if [ -f requirements.txt ]; then \\\n",
        "    echo \"requirements.txt detected → installing...\"; \\\n",
        "    pip install -q -r requirements.txt; \\\n",
        "  else \\\n",
        "    echo \"requirements.txt not found → skip\"; \\\n",
        "  fi\n",
        "\n",
        "# 공통 의존성 (누락 대비)\n",
        "!pip install -q opencv-python einops timm yacs tqdm thop tensorboard albumentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk7Uh92Pbz8N",
        "outputId": "40b89719-de25-4849-e367-2cd9b55769e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt not found → skip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Drive 경로 변수 등록 & 존재 여부 점검"
      ],
      "metadata": {
        "id": "zcelYGIMb7uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# === 경로 설정 ===\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/BOAZminiproject1\")\n",
        "\n",
        "DATA_ROOT = DRIVE_ROOT / \"fulldata\"  # rain/fog/dust 포함\n",
        "WEIGHT_BACKBONE = DRIVE_ROOT / \"MWFormer_weights\" / \"MWFormer_L\" / \"backbone.pth\"\n",
        "WEIGHT_STYLE    = DRIVE_ROOT / \"MWFormer_weights\" / \"pretrained_feature_extraction_network\" / \"style_filter.pth\"\n",
        "\n",
        "print(\"DATA_ROOT        :\", DATA_ROOT)\n",
        "print(\"WEIGHT_BACKBONE  :\", WEIGHT_BACKBONE)\n",
        "print(\"WEIGHT_STYLE     :\", WEIGHT_STYLE)\n",
        "\n",
        "# === 존재 여부 점검 ===\n",
        "assert DATA_ROOT.exists(), f\"데이터 폴더가 없습니다: {DATA_ROOT}\"\n",
        "assert WEIGHT_BACKBONE.exists(), f\"백본 가중치가 없습니다: {WEIGHT_BACKBONE}\"\n",
        "assert WEIGHT_STYLE.exists(),    f\"style_filter 가중치가 없습니다: {WEIGHT_STYLE}\"\n",
        "print(\"✅ 모든 경로가 정상입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ZLYb9Kb51F",
        "outputId": "d6ffc575-b1d2-4414-ea55-d14742244951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_ROOT        : /content/drive/MyDrive/BOAZminiproject1/fulldata\n",
            "WEIGHT_BACKBONE  : /content/drive/MyDrive/BOAZminiproject1/MWFormer_weights/MWFormer_L/backbone.pth\n",
            "WEIGHT_STYLE     : /content/drive/MyDrive/BOAZminiproject1/MWFormer_weights/pretrained_feature_extraction_network/style_filter.pth\n",
            "✅ 모든 경로가 정상입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "매칭 리스트 생성 스크립트 실행"
      ],
      "metadata": {
        "id": "0i6PY-LtcUmr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3단계: 드라이런(sanity check) 학습"
      ],
      "metadata": {
        "id": "PLzSCRgbqqdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === MWFormer 패치 올인원 셀 ===\n",
        "# - main_finetune.py\n",
        "#   (1) 체크포인트 유연 로더(_load_state_dict_flexible) 삽입\n",
        "#   (2) .module.state_dict() 사용부 치환\n",
        "#   (3) TrainingDataset 타입 0/1/2 → 3으로 통일\n",
        "#   (4) W&B 로깅: wandb.init / wandb.log(loss/lr/iter, initial PSNR) / wandb.finish()\n",
        "#      * AMP(GradScaler) 사용 중이면 scaler.update() 뒤에 로그, 아니면 opts.step() 뒤에 로그\n",
        "# - train_data_functions.py\n",
        "#   (5) 'is not 3' → '!= 3'\n",
        "#   (6) 리스트 파서: '두 칼럼 input  GT' 또는 '한 칼럼 input' 모두 지원\n",
        "#       + train_data_dir 끝에 '/' 강제 + length 출력\n",
        "# - utils_network.py\n",
        "#   (7) SSIM/PSNR에 data_range=1.0 지정(중복 방지 포함)\n",
        "\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "# ---------- 1) main_finetune.py 패치 ----------\n",
        "mf = Path(\"/content/MWFormer/main_finetune.py\")\n",
        "msrc = mf.read_text()\n",
        "\n",
        "# (1) 유연 로더 헬퍼 삽입 (import torch 바로 뒤)\n",
        "if \"_load_state_dict_flexible\" not in msrc:\n",
        "    helper = r'''\n",
        "from collections import OrderedDict\n",
        "\n",
        "def _load_state_dict_flexible(ckpt_path, map_location=\"cpu\"):\n",
        "    obj = torch.load(ckpt_path, map_location=map_location)\n",
        "    if hasattr(obj, \"state_dict\") and callable(getattr(obj, \"state_dict\")):\n",
        "        sd = obj.state_dict()\n",
        "    elif isinstance(obj, dict) and \"state_dict\" in obj and isinstance(obj[\"state_dict\"], (dict, OrderedDict)):\n",
        "        sd = obj[\"state_dict\"]\n",
        "    elif isinstance(obj, dict) and \"model\" in obj and isinstance(obj[\"model\"], (dict, OrderedDict)):\n",
        "        sd = obj[\"model\"]\n",
        "    elif isinstance(obj, (dict, OrderedDict)):\n",
        "        sd = obj\n",
        "    else:\n",
        "        try:\n",
        "            sd = obj.module.state_dict()\n",
        "        except Exception:\n",
        "            sd = obj\n",
        "    new_sd = OrderedDict()\n",
        "    for k, v in sd.items():\n",
        "        nk = k[7:] if k.startswith(\"module.\") else k\n",
        "        new_sd[nk] = v\n",
        "    return new_sd\n",
        "'''\n",
        "    msrc = re.sub(r\"(import\\s+torch[^\\n]*\\n)\", r\"\\1\" + helper + \"\\n\", msrc, count=1)\n",
        "\n",
        "# (2) .module.state_dict() → _load_state_dict_flexible(...)\n",
        "msrc = re.sub(\n",
        "    r\"torch\\.load\\(([^)]*)\\)\\.module\\.state_dict\\(\\)\",\n",
        "    r\"_load_state_dict_flexible(\\1)\",\n",
        "    msrc\n",
        ")\n",
        "\n",
        "# (3) Dataset 타입 통일: 0/1/2 → 3\n",
        "msrc = msrc.replace(\"TrainingDataset(0, \", \"TrainingDataset(3, \")\n",
        "msrc = msrc.replace(\"TrainingDataset(1, \", \"TrainingDataset(3, \")\n",
        "msrc = msrc.replace(\"TrainingDataset(2, \", \"TrainingDataset(3, \")\n",
        "\n",
        "# (4-1) W&B import\n",
        "if \"import wandb\" not in msrc:\n",
        "    msrc = msrc.replace(\"from datetime import datetime\", \"from datetime import datetime\\nimport wandb\")\n",
        "\n",
        "# (4-2) run_name 직후 wandb.init + LOG_EVERY\n",
        "if \"wandb.init(\" not in msrc:\n",
        "    msrc = msrc.replace(\n",
        "        \"run_name = f'{args.file_name}-{now}'\",\n",
        "        \"run_name = f'{args.file_name}-{now}'\\n\"\n",
        "        \"    # === W&B init ===\\n\"\n",
        "        \"    wandb.init(project='MWFormer', name=run_name,\\n\"\n",
        "        \"               config={\\n\"\n",
        "        \"                   'file_name': args.file_name,\\n\"\n",
        "        \"                   'num_steps': args.num_steps,\\n\"\n",
        "        \"                   'learning_rate': args.learning_rate,\\n\"\n",
        "        \"                   'crop_size': args.crop_size,\\n\"\n",
        "        \"                   'num_workers': args.num_workers,\\n\"\n",
        "        \"                   'snapshot_dir': args.snapshot_dir,\\n\"\n",
        "        \"               })\\n\"\n",
        "        \"    LOG_EVERY = 100  # wandb 로그 주기(steps)\\n\"\n",
        "    )\n",
        "\n",
        "# (4-3) 초기 PSNR wandb.log\n",
        "if \"val_psnr_initial\" not in msrc:\n",
        "    msrc = msrc.replace(\n",
        "        \"print('initial model PSNR: ', old_val_psnr)\",\n",
        "        \"print('initial model PSNR: ', old_val_psnr)\\n\"\n",
        "        \"    try:\\n\"\n",
        "        \"        wandb.log({'val_psnr_initial': float(old_val_psnr)}, step=0)\\n\"\n",
        "        \"    except Exception:\\n\"\n",
        "        \"        pass\"\n",
        "    )\n",
        "\n",
        "# (4-4) 학습 루프 내 wandb.log(loss/lr/iter)\n",
        "# AMP가 적용되어 있으면 scaler.update() 뒤에, 없으면 opts.step() 뒤에 삽입\n",
        "if \"scaler.update()\" in msrc and \"wandb.log({\" not in msrc:\n",
        "    msrc = msrc.replace(\n",
        "        \"scaler.update()\",\n",
        "        \"scaler.update()\\n\"\n",
        "        \"        # === W&B log ===\\n\"\n",
        "        \"        try:\\n\"\n",
        "        \"            if (i_iter % LOG_EVERY) == 0:\\n\"\n",
        "        \"                wandb.log({'loss': float(loss_p.detach().item()), 'lr': float(main_lr), 'iter': int(i_iter)})\\n\"\n",
        "        \"        except Exception:\\n\"\n",
        "        \"            pass\"\n",
        "    )\n",
        "elif \"wandb.log({\" not in msrc and \"opts.step()\" in msrc:\n",
        "    msrc = msrc.replace(\n",
        "        \"opts.step()\",\n",
        "        \"opts.step()\\n\"\n",
        "        \"        # === W&B log ===\\n\"\n",
        "        \"        try:\\n\"\n",
        "        \"            if (i_iter % LOG_EVERY) == 0:\\n\"\n",
        "        \"                wandb.log({'loss': float(loss_p.detach().item()), 'lr': float(main_lr), 'iter': int(i_iter)})\\n\"\n",
        "        \"        except Exception:\\n\"\n",
        "        \"            pass\"\n",
        "    )\n",
        "\n",
        "# (4-5) 종료 시 wandb.finish()\n",
        "if \"wandb.finish()\" not in msrc:\n",
        "    msrc += \"\\ntry:\\n    pass\\nfinally:\\n    import wandb as _w; _w.finish()\\n\"\n",
        "\n",
        "mf.write_text(msrc)\n",
        "print(\"✅ main_finetune.py 패치 완료 (유연 로더 + 타입 통일 + W&B 로깅)\")\n",
        "\n",
        "# ---------- 2) train_data_functions.py 패치 ----------\n",
        "tp = Path(\"/content/MWFormer/train_data_functions.py\")\n",
        "tsrc = tp.read_text()\n",
        "\n",
        "# (5) 'is not 3' 경고 수정\n",
        "tsrc = tsrc.replace(\" is not 3\", \" != 3\")\n",
        "\n",
        "# (6) 리스트 파서 교체 (with open(train_list) ~ self.train_data_dir 설정까지)\n",
        "lines = tsrc.splitlines()\n",
        "start_idx = None\n",
        "end_idx = None\n",
        "for i, ln in enumerate(lines):\n",
        "    if \"with open(train_list) as f:\" in ln and start_idx is None:\n",
        "        start_idx = i\n",
        "    if start_idx is not None and \"self.train_data_dir = train_data_dir\" in ln:\n",
        "        end_idx = i\n",
        "        break\n",
        "\n",
        "if start_idx is not None and end_idx is not None:\n",
        "    new_block = [\n",
        "        \"        with open(train_list) as f:\",\n",
        "        \"            contents = [ln.strip() for ln in f if ln.strip()]\",\n",
        "        \"\",\n",
        "        \"        input_names = []\",\n",
        "        \"        gt_names    = []\",\n",
        "        \"\",\n",
        "        \"        for ln in contents:\",\n",
        "        \"            parts = ln.split()  # 공백/탭 분리\",\n",
        "        \"            if len(parts) >= 2:\",\n",
        "        \"                # 두 칼럼: 0=입력, 1=GT\",\n",
        "        \"                inp_rel = parts[0].lstrip('/')\",\n",
        "        \"                gt_rel  = parts[1].lstrip('/')\",\n",
        "        \"                input_names.append(inp_rel)\",\n",
        "        \"                gt_names.append(gt_rel)\",\n",
        "        \"            else:\",\n",
        "        \"                # 한 칼럼: 입력만 → GT는 input→gt 치환\",\n",
        "        \"                inp_rel = parts[0].lstrip('/')\",\n",
        "        \"                gt_rel  = inp_rel.replace('/input/', '/gt/').replace('/GT/', '/gt/')\",\n",
        "        \"                input_names.append(inp_rel)\",\n",
        "        \"                gt_names.append(gt_rel)\",\n",
        "        \"\",\n",
        "        \"        self.input_names = input_names\",\n",
        "        \"        self.gt_names    = gt_names\",\n",
        "        \"        self.crop_size   = crop_size\",\n",
        "        \"        self.train_data_dir = train_data_dir if train_data_dir.endswith('/') else (train_data_dir + '/')\",\n",
        "        \"\",\n",
        "        \"        print('length of input names:', len(input_names))\",\n",
        "    ]\n",
        "    tsrc = \"\\n\".join(lines[:start_idx] + new_block + lines[end_idx+1:])\n",
        "else:\n",
        "    print(\"⚠️ 리스트 파서 블록을 찾지 못했습니다. 파일 구조가 달라졌을 수 있습니다. (패치 건너뜀)\")\n",
        "\n",
        "tp.write_text(tsrc)\n",
        "print(\"✅ train_data_functions.py 패치 완료 (리스트 파서 유연화)\")\n",
        "\n",
        "# ---------- 3) utils_network.py 패치 ----------\n",
        "up = Path(\"/content/MWFormer/utils_network.py\")\n",
        "usrc = up.read_text()\n",
        "\n",
        "# compare_ssim/compare_psnr → data_range=1.0 지정\n",
        "usrc = re.sub(r\"compare_ssim\\(([^)]*)\\)\", r\"compare_ssim(\\1, data_range=1.0)\", usrc)\n",
        "usrc = re.sub(r\"compare_psnr\\(([^)]*)\\)\", r\"compare_psnr(\\1, data_range=1.0)\", usrc)\n",
        "\n",
        "# 혹시 이전 중복 인자가 남아있다면 정리\n",
        "usrc = usrc.replace(\"data_range=1, data_range=1.0\", \"data_range=1.0\")\n",
        "usrc = usrc.replace(\"data_range=1.0, data_range=1.0\", \"data_range=1.0\")\n",
        "\n",
        "up.write_text(usrc)\n",
        "print(\"✅ utils_network.py 패치 완료 (SSIM/PSNR data_range=1.0)\")\n",
        "\n",
        "print(\"\\n🎉 모든 패치 완료! 이제 W&B 로깅과 유연한 데이터 로딩이 활성화되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGsvFpX_JjTW",
        "outputId": "ec74e437-8085-47c9-b7b5-49a7e1be0fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ main_finetune.py 패치 완료 (유연 로더 + 타입 통일 + W&B 로깅)\n",
            "✅ train_data_functions.py 패치 완료 (리스트 파서 유연화)\n",
            "✅ utils_network.py 패치 완료 (SSIM/PSNR data_range=1.0)\n",
            "\n",
            "🎉 모든 패치 완료! 이제 W&B 로깅과 유연한 데이터 로딩이 활성화되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/BOAZminiproject1\")\n",
        "SRC  = BASE / \"finetunning\" / \"train_pairs_joint.txt\"  # 전체 리스트 (두 칼럼)\n",
        "DST_DIR = BASE / \"fulldata\" / \"lists\"\n",
        "DST_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DST  = DST_DIR / \"train_pairs_joint.small.txt\"\n",
        "\n",
        "# 앞 800줄만 복사 (이미 있으면 건너뜀)\n",
        "if SRC.exists() and not DST.exists():\n",
        "    n = 800\n",
        "    with open(SRC) as f, open(DST, \"w\") as w:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= n: break\n",
        "            w.write(line)\n",
        "print(\"샘플 리스트 위치:\", DST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rstz4D76Ly0J",
        "outputId": "36df86a0-9660-4a13-f1d2-db8ea4e300d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플 리스트 위치: /content/drive/MyDrive/BOAZminiproject1/fulldata/lists/train_pairs_joint.small.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "up = Path(\"/content/MWFormer/utils_network.py\")\n",
        "src = up.read_text()\n",
        "\n",
        "# 잘못 들어간 중복 제거\n",
        "src = src.replace(\"data_range=1, data_range=1.0\", \"data_range=1.0\")\n",
        "src = src.replace(\"data_range=1.0, data_range=1.0\", \"data_range=1.0\")\n",
        "\n",
        "# 혹시 남아있을 중복 대비: \"data_range=1,\" -> \"data_range=1.0,\"\n",
        "src = src.replace(\"data_range=1,\", \"data_range=1.0,\")\n",
        "\n",
        "up.write_text(src)\n",
        "print(\"✅ utils_network.py 중복 data_range 인자 제거 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aH2OZCrMEnz",
        "outputId": "c2e0933f-bdcd-49de-fa35-9622b28c1ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ utils_network.py 중복 data_range 인자 제거 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 로컬 캐시 + 진행률/ETA + 마일스톤(20/40/60/80/100%) 자동 백업 ======\n",
        "from pathlib import Path\n",
        "import shutil, os, time, math, json, subprocess, datetime\n",
        "\n",
        "# === 경로 설정 ===\n",
        "DRIVE      = Path(\"/content/drive/MyDrive/BOAZminiproject1\")\n",
        "SRC_ROOT   = DRIVE / \"fulldata\"\n",
        "SRC_LIST   = SRC_ROOT / \"lists\" / \"train_pairs_joint.txt\"   # 두 칼럼 (input  gt)\n",
        "\n",
        "DST_ROOT   = Path(\"/content/fastdata\")                      # 캐시 타깃(로컬 SSD)\n",
        "DST_LIST   = DST_ROOT / \"lists\" / \"train_pairs_joint.txt\"   # 성공 쌍만 다시 기록\n",
        "\n",
        "# === 드라이브 백업 경로 (미러) ===\n",
        "BACKUP_DIR = DRIVE / \"fastdata_cache\"                       # 미러 폴더(덮어쓰기/증분)\n",
        "BACKUP_TAG_DIR = DRIVE / \"fastdata_cache_milestones\"        # 선택: 스냅샷(옵션)\n",
        "\n",
        "# === 캐시/로그 옵션 ===\n",
        "REPORT_EVERY      = 1000   # n쌍마다 로그\n",
        "REPORT_EVERY_SEC  = 10     # 또는 n초마다 로그\n",
        "RETRIES           = 6      # I/O 재시도\n",
        "BASE_DELAY        = 0.4    # 재시도 지연(지수 증가)\n",
        "MILESTONES        = [20, 40, 60, 80, 100]   # % 도달 시 백업\n",
        "MAKE_SNAPSHOT_COPY = False  # True면 각 마일스톤별 별도 스냅샷 폴더도 생성(용량 주의)\n",
        "\n",
        "# ====== Helper ======\n",
        "def safe_exists(p: Path, retries=RETRIES, base_delay=BASE_DELAY):\n",
        "    p = Path(p)\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            return p.exists()\n",
        "        except OSError:\n",
        "            time.sleep(base_delay * (i + 1))\n",
        "    return False\n",
        "\n",
        "def safe_getsize(p: Path, retries=RETRIES, base_delay=BASE_DELAY):\n",
        "    p = Path(p)\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            return os.path.getsize(p)\n",
        "        except OSError:\n",
        "            time.sleep(base_delay * (i + 1))\n",
        "    return None\n",
        "\n",
        "def same_size(src: Path, dst: Path):\n",
        "    s = safe_getsize(src)\n",
        "    d = safe_getsize(dst)\n",
        "    return (s is not None) and (d is not None) and (s == d)\n",
        "\n",
        "def copy2_with_retry(src: Path, dst: Path, retries=RETRIES, base_delay=BASE_DELAY, verify=True):\n",
        "    src = Path(src); dst = Path(dst)\n",
        "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "    last_err = None\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            shutil.copy2(src, dst)\n",
        "            if not verify or same_size(src, dst):\n",
        "                return True\n",
        "        except OSError as e:\n",
        "            last_err = e\n",
        "            time.sleep(base_delay * (i + 1))\n",
        "    # 마지막 검증\n",
        "    if verify and dst.exists() and same_size(src, dst):\n",
        "        return True\n",
        "    if last_err:\n",
        "        raise last_err\n",
        "    return False\n",
        "\n",
        "def fmt_time(sec):\n",
        "    if sec is None or math.isinf(sec) or sec < 0:\n",
        "        return \"--:--:--\"\n",
        "    h = int(sec // 3600); m = int((sec % 3600) // 60); s = int(sec % 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "def write_manifest(path: Path, payload: dict):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(payload, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "def rsync_available():\n",
        "    try:\n",
        "        out = subprocess.run([\"rsync\", \"--version\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        return out.returncode == 0\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "def backup_to_drive(src_dir: Path, dst_dir: Path, milestone_pct: int):\n",
        "    \"\"\"\n",
        "    /content/fastdata → Drive로 증분 백업(가능하면 rsync 사용).\n",
        "    milestone_pct: 진행률(정수)\n",
        "    \"\"\"\n",
        "    src_dir = Path(src_dir); dst_dir = Path(dst_dir)\n",
        "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    start = time.time()\n",
        "    print(f\"🔄 백업 시작({milestone_pct}%): {src_dir} → {dst_dir}\")\n",
        "\n",
        "    # 1) rsync가 있으면 rsync로 빠르게 동기화(증분)\n",
        "    if rsync_available():\n",
        "        # -a (archive), -r (recursive), -t (times), --delete(삭제 동기화), --update(새로운/수정된 파일만)\n",
        "        cmd = [\n",
        "            \"rsync\", \"-a\", \"--delete\", \"--update\",\n",
        "            f\"{str(src_dir).rstrip('/')}/\", f\"{str(dst_dir).rstrip('/')}/\"\n",
        "        ]\n",
        "        proc = subprocess.run(cmd)\n",
        "        if proc.returncode != 0:\n",
        "            print(\"⚠️ rsync 실패 → shutil로 폴백합니다.\")\n",
        "            _copytree_update(src_dir, dst_dir)\n",
        "    else:\n",
        "        # 2) rsync가 없으면 느리지만 파이썬으로 증분 복사\n",
        "        _copytree_update(src_dir, dst_dir)\n",
        "\n",
        "    # 마일스톤 마커/메타 저장\n",
        "    marker = dst_dir / f\"_milestone_{milestone_pct}p.txt\"\n",
        "    marker.write_text(f\"milestone: {milestone_pct}%\\nfinished_at: {datetime.datetime.now().isoformat()}\")\n",
        "\n",
        "    meta = {\n",
        "        \"milestone_pct\": milestone_pct,\n",
        "        \"finished_at\": datetime.datetime.now().isoformat()\n",
        "    }\n",
        "    write_manifest(dst_dir / \"cache_backup_meta.json\", meta)\n",
        "\n",
        "    # (옵션) 스냅샷 폴더 별도 생성\n",
        "    if MAKE_SNAPSHOT_COPY:\n",
        "        SNAP = Path(BACKUP_TAG_DIR) / f\"milestone_{milestone_pct:03d}p\"\n",
        "        print(f\"📦 스냅샷 저장: {SNAP}\")\n",
        "        if rsync_available():\n",
        "            SNAP.parent.mkdir(parents=True, exist_ok=True)\n",
        "            cmd2 = [\"rsync\", \"-a\", \"--delete\", \"--update\",\n",
        "                    f\"{str(dst_dir).rstrip('/')}/\", f\"{str(SNAP).rstrip('/')}/\"]\n",
        "            subprocess.run(cmd2)\n",
        "        else:\n",
        "            _copytree_update(dst_dir, SNAP)\n",
        "\n",
        "    took = fmt_time(time.time() - start)\n",
        "    print(f\"✅ 백업 완료({milestone_pct}%) | 소요: {took}\")\n",
        "\n",
        "def _copytree_update(src_root: Path, dst_root: Path):\n",
        "    \"\"\"dst에 같은 경로/이름이 있고 사이즈 같으면 스킵, 아니면 업데이트 복사\"\"\"\n",
        "    src_root = Path(src_root); dst_root = Path(dst_root)\n",
        "    for root, dirs, files in os.walk(src_root):\n",
        "        rel = os.path.relpath(root, src_root)\n",
        "        dst_dir = os.path.join(dst_root, rel) if rel != \".\" else str(dst_root)\n",
        "        os.makedirs(dst_dir, exist_ok=True)\n",
        "        for fn in files:\n",
        "            s = Path(root) / fn\n",
        "            d = Path(dst_dir) / fn\n",
        "            try:\n",
        "                if d.exists() and same_size(s, d):\n",
        "                    continue\n",
        "                shutil.copy2(s, d)\n",
        "            except Exception:\n",
        "                # 파일 단위 에러는 무시하고 계속 진행(대부분 일시적 I/O)\n",
        "                pass\n",
        "\n",
        "# ====== 리스트 읽기 ======\n",
        "assert safe_exists(SRC_LIST), f\"리스트가 보이지 않습니다: {SRC_LIST}\\n드라이브 마운트를 확인하세요.\"\n",
        "with open(SRC_LIST) as f:\n",
        "    raw_lines = [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "pairs_all = []\n",
        "for ln in raw_lines:\n",
        "    parts = ln.split()\n",
        "    if len(parts) >= 2:\n",
        "        pairs_all.append((parts[0].lstrip(\"/\"), parts[1].lstrip(\"/\")))\n",
        "TOTAL = len(pairs_all)\n",
        "print(f\"총 쌍 수: {TOTAL:,}\")\n",
        "\n",
        "# ====== 캐시 루프 ======\n",
        "ok_pairs, copied_files, skipped_files, missing, failed = 0, 0, 0, 0, 0\n",
        "pairs_ok_list = []\n",
        "\n",
        "start = time.time()\n",
        "last_report_t = start\n",
        "# 마일스톤 관리(한 번만 수행)\n",
        "pending_milestones = set(MILESTONES)\n",
        "\n",
        "# 미리 폴더 생성\n",
        "(DST_ROOT / \"lists\").mkdir(parents=True, exist_ok=True)\n",
        "BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "BACKUP_TAG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for idx, (inp_rel, gt_rel) in enumerate(pairs_all, 1):\n",
        "    s_inp, s_gt = SRC_ROOT / inp_rel, SRC_ROOT / gt_rel\n",
        "    d_inp, d_gt = DST_ROOT / inp_rel, DST_ROOT / gt_rel\n",
        "    d_inp.parent.mkdir(parents=True, exist_ok=True)\n",
        "    d_gt.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ok = True\n",
        "\n",
        "    # input\n",
        "    if safe_exists(s_inp):\n",
        "        if safe_exists(d_inp) and same_size(s_inp, d_inp):\n",
        "            skipped_files += 1\n",
        "        else:\n",
        "            try:\n",
        "                copy2_with_retry(s_inp, d_inp)\n",
        "                copied_files += 1\n",
        "            except OSError:\n",
        "                ok = False\n",
        "                failed += 1\n",
        "    else:\n",
        "        ok = False\n",
        "        missing += 1\n",
        "\n",
        "    # gt\n",
        "    if safe_exists(s_gt):\n",
        "        if safe_exists(d_gt) and same_size(s_gt, d_gt):\n",
        "            skipped_files += 1\n",
        "        else:\n",
        "            try:\n",
        "                copy2_with_retry(s_gt, d_gt)\n",
        "                copied_files += 1\n",
        "            except OSError:\n",
        "                ok = False\n",
        "                failed += 1\n",
        "    else:\n",
        "        ok = False\n",
        "        missing += 1\n",
        "\n",
        "    if ok:\n",
        "        ok_pairs += 1\n",
        "        pairs_ok_list.append(f\"{inp_rel} {gt_rel}\")\n",
        "\n",
        "    # 진행률/ETA 출력\n",
        "    now = time.time()\n",
        "    need_time_report = (idx % REPORT_EVERY == 0) or (now - last_report_t >= REPORT_EVERY_SEC)\n",
        "    if need_time_report:\n",
        "        elapsed = now - start\n",
        "        pct_idx = idx / TOTAL * 100 if TOTAL else 0.0\n",
        "        pct_ok  = ok_pairs / TOTAL * 100 if TOTAL else 0.0\n",
        "        sec_per_pair = elapsed / idx if idx else float(\"inf\")\n",
        "        eta_sec = sec_per_pair * (TOTAL - idx)\n",
        "        print(\n",
        "            f\"[{idx:,}/{TOTAL:,}] \"\n",
        "            f\"done={ok_pairs:,} ({pct_ok:5.1f}%)  \"\n",
        "            f\"progress={pct_idx:5.1f}%  \"\n",
        "            f\"copied={copied_files:,}  skipped={skipped_files:,}  \"\n",
        "            f\"missing={missing:,}  failed={failed:,}  \"\n",
        "            f\"elapsed={fmt_time(elapsed)}  ETA={fmt_time(eta_sec)}\"\n",
        "        )\n",
        "        last_report_t = now\n",
        "\n",
        "    # === 마일스톤 도달 시 자동 백업 ===\n",
        "    done_pct_int = int(ok_pairs / TOTAL * 100) if TOTAL else 0\n",
        "    hit = sorted([m for m in pending_milestones if done_pct_int >= m])\n",
        "    if hit:\n",
        "        # 중복 방지: 가장 낮은 마일스톤부터 순서대로 실행 후 pending에서 제거\n",
        "        for m in hit:\n",
        "            try:\n",
        "                backup_to_drive(DST_ROOT, BACKUP_DIR, m)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ 마일스톤 {m}% 백업 실패: {e}\")\n",
        "            pending_milestones.discard(m)\n",
        "\n",
        "# 리스트 저장(성공 쌍만)\n",
        "DST_LIST.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(DST_LIST, \"w\") as w:\n",
        "    w.write(\"\\n\".join(pairs_ok_list))\n",
        "\n",
        "elapsed = time.time() - start\n",
        "print(\"\\n✅ 로컬 캐시 완료\")\n",
        "print(f\"쌍(OK)   : {ok_pairs:,} / {TOTAL:,}\")\n",
        "print(f\"복사(파일): {copied_files:,}  | 스킵: {skipped_files:,}  | 누락: {missing:,}  | 실패: {failed:,}\")\n",
        "print(f\"경과시간  : {fmt_time(elapsed)}\")\n",
        "print(\"로컬 리스트:\", DST_LIST)\n",
        "\n",
        "# 최종 마니페스트 + 마지막 백업(혹시 100% 마일스톤을 못 탔다면 한 번 더)\n",
        "manifest = {\n",
        "    \"ok_pairs\": ok_pairs,\n",
        "    \"total_pairs\": TOTAL,\n",
        "    \"elapsed\": elapsed,\n",
        "    \"finished_at\": datetime.datetime.now().isoformat(),\n",
        "}\n",
        "write_manifest(DST_ROOT / \"cache_progress.json\", manifest)\n",
        "\n",
        "if 100 in pending_milestones:\n",
        "    try:\n",
        "        backup_to_drive(DST_ROOT, BACKUP_DIR, 100)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 최종 백업 실패: {e}\")\n",
        "\n",
        "print(\"🎉 캐싱 & 마일스톤 백업 종료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "GKZya7tjOSel",
        "outputId": "ec2d57f0-b604-4c5b-b1c0-cac7ef444a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "리스트가 보이지 않습니다: /content/drive/MyDrive/BOAZminiproject1/fulldata/lists/train_pairs_joint.txt\n드라이브 마운트를 확인하세요.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1585099026.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;31m# ====== 리스트 읽기 ======\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0msafe_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSRC_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"리스트가 보이지 않습니다: {SRC_LIST}\\n드라이브 마운트를 확인하세요.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSRC_LIST\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mraw_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mln\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: 리스트가 보이지 않습니다: /content/drive/MyDrive/BOAZminiproject1/fulldata/lists/train_pairs_joint.txt\n드라이브 마운트를 확인하세요."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##캐싱 끝나면 무조건 드라이브에 넣을 것!!!!"
      ],
      "metadata": {
        "id": "Y_uKQWZ-BneG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 수동 드라이브 저장\n",
        "# !cp -r /content/fastdata /content/drive/MyDrive/BOAZminiproject1/fastdata_cache"
      ],
      "metadata": {
        "id": "ToArWns-Bmfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 나중에 불러오기\n",
        "!cp -r /content/drive/MyDrive/BOAZminiproject1/fastdata_cache /content/fastdata"
      ],
      "metadata": {
        "id": "rGQjyl2yEwrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최소 패치(AMP + 작은 배치 + 드라이브 I/O 재시도)"
      ],
      "metadata": {
        "id": "nF0DjW3QKs96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 최소 패치: main_finetune(AMP/작은배치) + train_data_functions(open_with_retry) ===\n",
        "from pathlib import Path, re as _re\n",
        "\n",
        "# ---------- main_finetune.py ----------\n",
        "mp = Path(\"/content/MWFormer/main_finetune.py\")\n",
        "msrc = mp.read_text()\n",
        "\n",
        "# (A) AMP import (중복 방지)\n",
        "if \"from torch.cuda.amp import autocast, GradScaler\" not in msrc:\n",
        "    msrc = msrc.replace(\n",
        "        \"from datetime import datetime\",\n",
        "        \"from datetime import datetime\\nfrom torch.cuda.amp import autocast, GradScaler\"\n",
        "    )\n",
        "\n",
        "# (B) scaler 초기화 (중복 방지)\n",
        "if \"scaler = GradScaler()\" not in msrc:\n",
        "    msrc = msrc.replace(\n",
        "        \"model.train()\",\n",
        "        \"model.train()\\n\\n    # AMP scaler (메모리 절약)\\n    scaler = GradScaler()\"\n",
        "    )\n",
        "\n",
        "# (C) 학습 루프의 backward/step을 AMP로 감싸기 (패턴이 다르면 건너뜀)\n",
        "if \"scaler.scale(\" not in msrc:\n",
        "    msrc = _re.sub(\n",
        "        r\"opts\\.zero_grad\\(\\)\\s*\\n([\\s\\S]*?)loss_p\\s*=\\s*loss_calc\\((.*?)\\)\\s*\\n\\s*loss_p\\.backward\\(\\)\\s*\\n\\s*opts\\.step\\(\\)\",\n",
        "        (\n",
        "            \"opts.zero_grad()\\n\"\n",
        "            \"\\\\1with autocast():\\n\"\n",
        "            \"            loss_p = loss_calc(\\\\2)\\n\"\n",
        "            \"        scaler.scale(loss_p).backward()\\n\"\n",
        "            \"        scaler.step(opts)\\n\"\n",
        "            \"        scaler.update()\"\n",
        "        ),\n",
        "        msrc,\n",
        "        count=1\n",
        "    )\n",
        "\n",
        "# (D) DataLoader 배치 크기 최소화(10/11/4 → 2), 여러 곳에 있을 수 있어 치환\n",
        "msrc = msrc.replace(\"batch_size=10\", \"batch_size=2\")\n",
        "msrc = msrc.replace(\"batch_size=11\", \"batch_size=2\")\n",
        "msrc = msrc.replace(\"batch_size=4\",  \"batch_size=2\")\n",
        "\n",
        "mp.write_text(msrc)\n",
        "print(\"✅ main_finetune.py: AMP/작은배치 패치 완료\")\n",
        "\n",
        "# ---------- train_data_functions.py ----------\n",
        "tp = Path(\"/content/MWFormer/train_data_functions.py\")\n",
        "tsrc = tp.read_text()\n",
        "\n",
        "# (E) open_with_retry 헬퍼 삽입(중복 방지)\n",
        "if \"def open_with_retry(\" not in tsrc:\n",
        "    helper = r\"\"\"\n",
        "\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "def open_with_retry(img_path, max_retries=6, delay=0.4):\n",
        "    last_err = None\n",
        "    for _ in range(max_retries):\n",
        "        try:\n",
        "            with Image.open(img_path) as im:\n",
        "                return im.convert('RGB')\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            time.sleep(delay)\n",
        "    raise last_err\n",
        "\"\"\"\n",
        "    tsrc = tsrc.replace(\"ImageFile.LOAD_TRUNCATED_IMAGES = True\", \"ImageFile.LOAD_TRUNCATED_IMAGES = True\\n\" + helper)\n",
        "\n",
        "# (F) 실제 이미지 로딩 부분을 open_with_retry로 교체(존재 시에만)\n",
        "tsrc = _re.sub(\n",
        "    r\"input_img = Image\\.open\\(self\\.train_data_dir \\+ input_name\\)\\s*?\\n\\s*try:\\s*?\\n\\s*gt_img = Image\\.open\\(self\\.train_data_dir \\+ gt_name\\)\\s*?\\n\\s*except:\\s*?\\n\\s*gt_img = Image\\.open\\(self\\.train_data_dir \\+ gt_name\\)\\.convert\\('RGB'\\)\",\n",
        "    \"input_img = open_with_retry(self.train_data_dir + input_name)\\n        gt_img    = open_with_retry(self.train_data_dir + gt_name)\",\n",
        "    tsrc\n",
        ")\n",
        "\n",
        "# (G) 경고 수정: 'is not 3' → '!= 3'\n",
        "tsrc = tsrc.replace(\" is not 3\", \" != 3\")\n",
        "\n",
        "tp.write_text(tsrc)\n",
        "print(\"✅ train_data_functions.py: open_with_retry/경고수정 패치 완료\")"
      ],
      "metadata": {
        "id": "ex9PTsE6K7VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "경로/리스트 점검(빠르게)"
      ],
      "metadata": {
        "id": "5TO_Dz0JK8Zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "FAST_ROOT = Path(\"/content/fastdata\")\n",
        "LIST_PATH = FAST_ROOT / \"lists\" / \"train_pairs_joint.txt\"\n",
        "\n",
        "print(\"fastdata 존재:\", FAST_ROOT.exists())\n",
        "print(\"train_pairs_joint.txt 존재:\", LIST_PATH.exists())\n",
        "if LIST_PATH.exists():\n",
        "    print(\"라인 수:\", sum(1 for _ in open(LIST_PATH)))"
      ],
      "metadata": {
        "id": "hSPAiu31K-n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 실행(캐시 사용, 안정 세팅)"
      ],
      "metadata": {
        "id": "s3VPCRwrLAJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MWFormer\n",
        "\n",
        "!python main_finetune.py \\\n",
        "  -train_data_dir /content/fastdata/ \\\n",
        "  -labeled_name lists/train_pairs_joint.txt \\\n",
        "  -restore-from-stylefilter /content/drive/MyDrive/BOAZminiproject1/MWFormer_weights/pretrained_feature_extraction_network/style_filter.pth \\\n",
        "  -restore-from /content/drive/MyDrive/BOAZminiproject1/MWFormer_weights/MWFormer_L/backbone.pth \\\n",
        "  -num-workers 2 \\\n",
        "  -crop_size 256 256 \\\n",
        "  -save-pred-every 10000 \\\n",
        "  -loss_save_step 10000 \\\n",
        "  -snapshot-dir /content/drive/MyDrive/BOAZminiproject1/finetunning/snapshots \\\n",
        "  -file-name MWFormer_L_wandb_fast"
      ],
      "metadata": {
        "id": "0CS2WiTLLBR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}